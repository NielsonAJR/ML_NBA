---
title: "Ajuste e Avaliação do Modelo"
lang: pt
message: false
warning: false
linkcolor: black
urlcolor: black
---



```{r}
#| echo: false

library(hoopR) # Banco de Dados
library(tidyverse) # Framework do tidyverse
library(tidymodels) # Framework de modelagem
library(skimr) # Estatística descritiva rápida
library(DataExplorer) # Exploração do conjunto de dados
library(corrplot) # Gráfico de correlação
library(GGally) # Gráficos adicionais com estrutura ggplot2
library(stringr) # Para lidar com strings
library(glmnet) # LASSO, Ridge e Rede Elástica
library(MASS) # Discriminante Linear (LDA) e Quadrático (RL)
library(recipes) # Pré-processamento dos dados
library(class) #knn
library(themis) # Balanceamento de dados
library(discrim) # lda, qda
library(kknn) # (Kernel) K-NN
library(finetune) # Otimização fina de hiperparâmetros
library(gt)
library(naivebayes)
library(knitr)
library(corrplot)


ggplot2::theme_set(theme_minimal()) # Ajustando Tema

dados_analise <- read.csv2("includes/nba.csv", sep = ";") 

dados_analise <- dados_analise |>
  mutate(
    PTS = as.numeric(PTS),
    AGE = as.numeric(AGE),
    AST = as.numeric(AST),
    REB = as.numeric(REB),
    Position = as.factor(Position),
    FG_PCT = as.numeric(FG_PCT),
    FG3_PCT = as.numeric(FG3_PCT),
    FT_PCT = as.numeric(FT_PCT)
  ) |>
  dplyr::select(-TEAM_ABBREVIATION, -PLAYER_NAME)

```


## Preparação dos Dados

- Divisão: 70% treino e 30% teste
- Variável resposta: **Position**


```{r}

set.seed(16723)

dados_analise_split <- initial_split(dados_analise, prop = .7, strata = Position)
train_data <- training(dados_analise_split)
test_data <- testing(dados_analise_split)

```

## Feature Engineering e Preparação dos Dados

### Objetivo da Feature Engineering

- Melhorar a capacidade preditiva do modelo
- Representar de forma mais fiel os papéis funcionais desempenhados pelos atletas em quadra
- Melhorar a separabilidade entre posições híbridas

#### AST_TOV_RATIO

- Definido como a razão entre as assistências (AST) e turnovers (TOV).
- Mede a eficiência na tomada de decisão e no controle da posse de bola.
- Amplamente utilizada para avaliação de organizadores ofensivos.
- O uso do **0.1** evita a divisão por zero.

#### REB_HEIGTH_INTER

- Interação entre os rebotes e a altura do jogador
- Diferencia jogadores altos dominantes no rebote de jogadores altos pouco eficientes
- Permite identificar reboteadores eficientes independentemente da altura


#### PLAYMAKER_SCORE

- Calculada como a diferença entre as versões padronizadas de AST e TOV.
- Distingue criadores eficientes de jogadores propensos a erros.
- Relevante para armadores e alas com função de criação.  


#### RIM_PROTECT 

- Indicador composto de presença defensiva no garrafão.
- Combina controle de rebotes e proteção de cesta
- Característico de pivôs e alas-pivôs defensivos

#### PTS_EFF

- Representa pontuação ajustada pela eficiência de arremesso
- Penaliza volume ofensivo ineficiente
- Distingue scorers eficientes de scorers de alto volume e baixo aproveitamento

### Pré-Processamento

```{r}

dados_analise_rec <- recipe(Position ~ ., data = train_data) |>
  
  step_mutate(
    AST_TOV_RATIO = AST / (TOV + 0.1),
    REB_HEIGHT_INTER = REB * Altura,
    PLAYMAKER_SCORE = AST - TOV,
    RIM_PROTECT = REB + BLK,
    PTS_EFF = PTS * FG_PCT) |>  
  step_YeoJohnson(all_numeric_predictors()) |> # Transformação Yeo-Johnson
  step_normalize(all_numeric_predictors()) |> # normaliza variáveis numéricas para terem média 0 e variância 1
  step_corr(all_numeric_predictors(), threshold = 0.8,
            method = "spearman"
  ) # remove preditores que tenham alta correlação com algum outro preditor

```



```{r}

prepped_data <- dados_analise_rec |> # usa a receita
  prep() |> # aplica a receita no conjunto de treinamento
  juice()# extrai apenas o dataframe preprocessado

```


### Conjunto de Validação

Utilizando o método *k-fold cross validation* para construir um conjunto de validação com *k-folds*. Considerando *k = 10*.

```{r}

cv_folds <- vfold_cv(train_data, v = 10, strata = Position)

```


### Otimização de Hiperparâmetros



```{r}

knn_spec <- nearest_neighbor(neighbors = tune()) %>% # K-NN
  set_engine("kknn")%>%
  set_mode("classification")

nbayes_spec <- naive_Bayes() %>% # Naive Bayes
  set_engine("naivebayes") %>%
  set_mode("classification")


multinom_spec <- multinom_reg() %>% # Reg Multinominal
  set_engine("nnet") %>% 
  set_mode("classification")

lda_spec <- discrim_linear() %>% # Linear discriminant analysis
  set_engine("MASS") %>%
  set_mode("classification")

qda_spec <- discrim_quad() %>% # Quadratic discriminant analysis
  set_engine("MASS") %>%
  set_mode("classification")


```

```{r}

wf = workflow_set(
  preproc = list(dados_analise_rec),
  models = list(
    knn_fit = knn_spec,
    nbayes_fit = nbayes_spec,
    linear_fit = multinom_spec,
    lda_fit = lda_spec,
    qda_fit = qda_spec
  )
) %>%
  mutate(wflow_id = gsub("(recipe_)", "", wflow_id))


```


```{r}

grid_ctrl = control_grid(
  save_pred = TRUE,
  parallel_over = "resamples",
  save_workflow = TRUE
)
grid_results = wf %>%
  workflow_map(
    seed = 16723,
    resamples = cv_folds,
    grid = 10,
    control = grid_ctrl
  )

```

Usando a acurácia no conjunto de validão de acordo com o melhor conjunto de hiperparâmetros obtido para cada modelo.

```{r}

autoplot(grid_results, metric = "accuracy")

```

Ordenando pelos melhores

```{r}

autoplot(grid_results, select_best = TRUE ,metric = "accuracy")

```

Utilizando outras métricas para avaliar

```{r}

autoplot(grid_results)

```

Ordenando os modelos pela métrica de acurácia no conjunto de Validação

```{r}

results_acc = workflowsets::rank_results(grid_results,
                                         select_best = TRUE,
                                         rank_metric = "accuracy") %>%
  filter(.metric == "accuracy") %>%
  dplyr::select(wflow_id, mean, std_err, model, rank)
results_acc %>% gt()

```

Escolhendo o melhor conjunto de hiperparâmetros para cada modelo de acordo com a acurácia no conjunto de validação.

```{r}

best_set_linear = grid_results %>% 
  extract_workflow_set_result("linear_fit") %>% 
  select_best(metric = "accuracy")
best_set_knn = grid_results %>% 
  extract_workflow_set_result("knn_fit") %>% 
  select_best(metric = "accuracy")
best_set_nbayes = grid_results %>%
  extract_workflow_set_result("nbayes_fit") %>% 
  select_best(metric = "accuracy")
best_set_lda = grid_results %>% 
  extract_workflow_set_result("lda_fit") %>% 
  select_best(metric = "accuracy")
best_set_qda = grid_results %>% 
  extract_workflow_set_result("qda_fit") %>% 
  select_best(metric = "accuracy")

```


## Avaliação dos modelos no conjunto de teste


```{r}

test_results <- function(rc_rslts, fit_obj, par_set, split_obj) {
  res <- rc_rslts %>%
    extract_workflow(fit_obj) %>%
    finalize_workflow(par_set) %>%
    last_fit(split = split_obj,
             metrics = metric_set(
               accuracy,roc_auc,
               f_meas,precision,
               recall,spec,kap))
  res
}


```

```{r}

test_results_linear = test_results(grid_results,"linear_fit",best_set_linear,dados_analise_split)
test_results_knn = test_results(grid_results,"knn_fit",best_set_knn,dados_analise_split)
test_results_nbayes = test_results(grid_results,"nbayes_fit",best_set_nbayes,dados_analise_split)
test_results_lda = test_results(grid_results,"lda_fit",best_set_lda,dados_analise_split)
test_results_qda = test_results(grid_results,"qda_fit",best_set_qda,dados_analise_split)


```


```{r}

metrics_table = rbind(
  collect_metrics(test_results_linear)$.estimate,
  collect_metrics(test_results_knn)$.estimate,
  collect_metrics(test_results_nbayes)$.estimate,
  collect_metrics(test_results_lda)$.estimate,
  collect_metrics(test_results_qda)$.estimate
)

metrics_table <- round(metrics_table, 4)
rnms = c("multi_reg","k_nn","naive_bayes", "lin_discr","quad_discr")
metrics_table <- cbind(rnms, metrics_table)
metrics_table <- metrics_table %>% dplyr::as_tibble()


```


```{r}

colnames(metrics_table) = c("method","acc","roc_auc","f_meas",
                            "precision","recall","spec","kappa")


```


```{r}


metrics_table %>%
  arrange(desc(acc),desc(roc_auc),desc(f_meas),desc(kappa)) %>%
  gt()

```





